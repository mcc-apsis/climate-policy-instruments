{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python                                                                                                                                                                                        \n",
    "\n",
    "# Import libraries                                                                                                                                                                                           \n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "class args():\n",
    "    pass\n",
    "\n",
    "args = args\n",
    "args.n_splits=3\n",
    "args.model_name = \"svm\"\n",
    "args.y_prefix = \"INCLUDE\"\n",
    "args.y_prefix = \"6 -\"\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Establish what task number we have if running from slurm, otherwise just get a random number                                                                                                               \n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    test = False\n",
    "except:\n",
    "    import random\n",
    "    rank = random.randint(0,args.n_splits**2)\n",
    "    print(rank)\n",
    "    test = True\n",
    "\n",
    "rank_i = rank//args.n_splits\n",
    "rank_j = rank%args.n_splits\n",
    "\n",
    "# Import the rest of the libraries                                                                                                                                                                           \n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "import pickle\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "# Load data                                                                                                                                                                                                  \n",
    "df = pd.read_csv('../data/0_labelled_documents.csv')\n",
    "\n",
    "df = (df\n",
    "      .sort_values('id')\n",
    "      .sample(frac=1, random_state=1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9 (default, Mar 15 2022, 13:55:28) \n",
      "[GCC 8.4.0]\n",
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH 100 documents\n",
      "['8 - 01. AFOLU', '8 - 02. Buildings', '8 - 03. Industry', '8 - 04. Energy', '8 - 05. Transport', '8 - 06. Waste', '8 - 15. Cross-sectoral', '8 - 08. Freshwater resources']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args.y_prefix = \"8 \"\n",
    "if test:\n",
    "    print(\"TESTING WITH 100 documents\")\n",
    "    #df = df.head(150)\n",
    "\n",
    "\n",
    "if len(args.y_prefix) < 2:\n",
    "    args.y_prefix+=\" \"\n",
    "cols = [x for x in df.columns if re.match(f\"^{args.y_prefix}\",x)]\n",
    "print(cols)\n",
    "num_labels=len(cols)\n",
    "\n",
    "\n",
    "# If the target is inclusion, use only those documents for which we have a non-na value                                                                                                                      \n",
    "# Otherwise, only use those documents which are included                                                                                                                                                     \n",
    "# also define what subset is to be treated as a random representative sample                                                                                                                                 \n",
    "# For labels beyond inclusion, we treat all those that are representative of the included                                                                                                                    \n",
    "# studies as representative                                                                                                                                                                                  \n",
    "\n",
    "if \"INCLUDE\" in args.y_prefix:\n",
    "    df = df.loc[pd.notna(df[\"INCLUDE\"]),:].reset_index(drop=True)\n",
    "    df['random'] = df['representative_sample']\n",
    "else:\n",
    "    df = df[df['INCLUDE']==1]\n",
    "    df['random'] = df['representative_relevant']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 - 01. AFOLU\n",
      "8 - 02. Buildings\n",
      "8 - 03. Industry\n",
      "8 - 04. Energy\n",
      "8 - 05. Transport\n",
      "8 - 06. Waste\n",
      "8 - 15. Cross-sectoral\n",
      "8 - 08. Freshwater resources\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cdf5347d0aa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#class_weight.append({0:1, 1:cw})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "if \"INCLUDE\" in args.y_prefix:\n",
    "    df = df.loc[pd.notna(df[\"INCLUDE\"]),:].reset_index(drop=True)\n",
    "    df['random'] = df['representative_sample']\n",
    "else:\n",
    "    df = df[df['INCLUDE']==1]\n",
    "    df['random'] = df['representative_relevant']\n",
    "\n",
    "\n",
    "# Turn the columns into target variables and get class-weights to counteract class imbalances                                                                           \n",
    "if len(cols)==1:\n",
    "    scorer = \"f1\"\n",
    "    y_var = cols[0]\n",
    "    df = df.loc[pd.notna(df[y_var]),:].reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    df['labels'] = list(df[y_var].values.astype(int))\n",
    "    y = df['labels']\n",
    "    cw = df[(df['random']==1) & (df[y_var]==0)].shape[0] / df[(df['random']==1) & (df[y_var]==1)].shape[0]\n",
    "    class_weight={0:1, 1:cw}\n",
    "    scorer = \"F1\"\n",
    "else:\n",
    "    scorer = \"f1_macro\"\n",
    "    num_labels = len(cols)\n",
    "    df = df.replace(2,1)\n",
    "    df['labels'] = list(df[cols].values.astype(int))\n",
    "    df = df.dropna(subset=cols)\n",
    "    df = df.reset_index(drop=True)\n",
    "    y = np.matrix(df[cols])\n",
    "\n",
    "    scorer = \"f1_macro\"\n",
    "    #class_weight = []\n",
    "    class_weight = {}\n",
    "    for i, t in enumerate(cols):\n",
    "        print(t)\n",
    "        cw = df[(df['random']==1) & (df[t]==0)].shape[0] / df[(df['random']==1) & (df[t]==1)].shape[0]\n",
    "        #class_weight.append({0:1, 1:cw}) \n",
    "        class_weight[i] = cw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv_setup as cvs\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if len(cols)>1:\n",
    "    pipeline = cvs.mpipeline\n",
    "    parameters = cvs.mparameters\n",
    "    for p in parameters:\n",
    "        p['clf__estimator__class_weight'] = ['balanced',None]\n",
    "else:\n",
    "    pipeline = cvs.pipeline\n",
    "    parameters = cvs.parameters\n",
    "    for p in parameters:\n",
    "        p['clf__class_weight'] = ['balanced',class_weight]\n",
    "\n",
    "# for p in parameters:\n",
    "#     p['clf__estimator__class_weight'] = ['balanced',class_weight]\n",
    "\n",
    "nonrandom_index = df[df['random']!=1].index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vect__max_df': (0.75,),\n",
       "  'vect__min_df': (10,),\n",
       "  'vect__ngram_range': ((1, 2),),\n",
       "  'clf__estimator__kernel': ['rbf'],\n",
       "  'clf__estimator__gamma': (0.0001,),\n",
       "  'clf__estimator__C': (100.0,),\n",
       "  'clf__estimator__class_weight': (None,)},\n",
       " {'vect__max_df': (75,),\n",
       "  'vect__min_df': (10,),\n",
       "  'vect__ngram_range': ((1, 2),),\n",
       "  'clf__estimator__kernel': ['linear'],\n",
       "  'clf__estimator__C': (100.0,),\n",
       "  'clf__estimator__class_weight': (None,)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in parameters:\n",
    "    for key, value in p.items():\n",
    "        if len(value) > 1:\n",
    "            p[key] = (value[1],)\n",
    "        #p[key] = value[0]\n",
    "        pass\n",
    "        \n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-6-e124ec8baa94>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e124ec8baa94>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    inner_cv = cvs.KFoldRandom(args.n_splits, train, nonrandom_index, discard=False)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "args.resume = \"False\"\n",
    "\n",
    "outer_cv = cvs.KFoldRandom(args.n_splits, df.index, nonrandom_index, discard=False)\n",
    "\n",
    "for k, (train, test) in enumerate(outer_cv):\n",
    "    print(k)\n",
    "    if k!=rank_j:\n",
    "        continue\n",
    "    fname = f'cv/df_{df.shape[0]}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "    if args.resume == \"True\":\n",
    "        inner_scores = pd.read_csv(fname)\n",
    "        best_model = inner_scores.sort_values('rank_test_score').to_dict('records')[0]\n",
    "        if best_model['param_clf__class_weight'] != \"balanced\":\n",
    "            best_model['param_clf__class_weight'] = ast.literal_eval(best_model['param_clf__class_weight'])\n",
    "        clf = Pipeline([\n",
    "            ('vect', TfidfVectorizer(\n",
    "                max_df=best_model['param_vect__max_df'],\n",
    "                min_df=best_model['param_vect__min_df'],\n",
    "                ngram_range=ast.literal_eval(best_model['param_vect__ngram_range'])\n",
    "            )),\n",
    "            ('clf', SVC(\n",
    "                probability=True,\n",
    "                C=best_model['param_clf__C'],\n",
    "                class_weight=best_model['param_clf__class_weight'],\n",
    "                kernel=best_model['param_clf__kernel'],\n",
    "                gamma=best_model['param_clf__gamma']\n",
    "            )),\n",
    "        ])\n",
    "        clf.fit(df.loc[train,'content'],y[train,:])\n",
    "    else:\n",
    "        inner_cv = cvs.KFoldRandom(args.n_splits, train, nonrandom_index, discard=False)\n",
    "        for a,b in inner_cv:\n",
    "            \n",
    "            #print(y[a,:].sum(axis=0))\n",
    "            #print(y[b,:].sum(axis=0))\n",
    "        inner_cv = cvs.KFoldRandom(args.n_splits, train, nonrandom_index, discard=False)\n",
    "        #clf = GridSearchCV(pipeline, parameters, scoring=\"f1\", n_jobs=8, verbose=1, cv=inner_cv)                                                                       \n",
    "        clf = GridSearchCV(pipeline, parameters, scoring=scorer, n_jobs=8, verbose=1, cv=inner_cv)\n",
    "        print(df.loc[train,'labels'])\n",
    "        clf.fit(df.loc[train, 'content'].values, y[train,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(b) & set(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict_proba(df.loc[test,'content'])\n",
    "eps = cvs.evaluate_preds(y[test], y_preds, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC AUC micro': 1.0,\n",
       " 'F1 micro': 0.9430523917995445,\n",
       " 'precision micro': 1.0,\n",
       " 'recall micro': 0.8922413793103449,\n",
       " 'ROC AUC macro': 1.0,\n",
       " 'F1 macro': 0.8,\n",
       " 'precision macro': 0.8,\n",
       " 'recall macro': 0.8,\n",
       " 'ROC AUC weighted': 1.0,\n",
       " 'F1 weighted': 0.8922413793103449,\n",
       " 'precision weighted': 0.8922413793103449,\n",
       " 'recall weighted': 0.8922413793103449,\n",
       " 'ROC AUC samples': nan,\n",
       " 'F1 samples': 0.8977498691784406,\n",
       " 'precision samples': 0.9230769230769231,\n",
       " 'recall samples': 0.8841575091575092,\n",
       " 'ROC AUC - 4 - 1. Economic instruments': 1.0,\n",
       " 'precision - 4 - 1. Economic instruments': 1.0,\n",
       " 'recall - 4 - 1. Economic instruments': 1.0,\n",
       " 'F1 - 4 - 1. Economic instruments': 1.0,\n",
       " 'accuracy - 4 - 1. Economic instruments': 1.0,\n",
       " 'n_target - 4 - 1. Economic instruments': 111.0,\n",
       " 'ROC AUC - 4 - 2. Regulatory Instruments': 1.0,\n",
       " 'precision - 4 - 2. Regulatory Instruments': 0.0,\n",
       " 'recall - 4 - 2. Regulatory Instruments': 0.0,\n",
       " 'F1 - 4 - 2. Regulatory Instruments': 0.0,\n",
       " 'accuracy - 4 - 2. Regulatory Instruments': 0.8626373626373627,\n",
       " 'n_target - 4 - 2. Regulatory Instruments': 25.0,\n",
       " 'ROC AUC - 4 - 3. Information, education and training': 1.0,\n",
       " 'precision - 4 - 3. Information, education and training': 1.0,\n",
       " 'recall - 4 - 3. Information, education and training': 1.0,\n",
       " 'F1 - 4 - 3. Information, education and training': 1.0,\n",
       " 'accuracy - 4 - 3. Information, education and training': 1.0,\n",
       " 'n_target - 4 - 3. Information, education and training': 6.0,\n",
       " 'ROC AUC - 4 - 4. Governance, strategies and targets': 1.0,\n",
       " 'precision - 4 - 4. Governance, strategies and targets': 1.0,\n",
       " 'recall - 4 - 4. Governance, strategies and targets': 1.0,\n",
       " 'F1 - 4 - 4. Governance, strategies and targets': 1.0,\n",
       " 'accuracy - 4 - 4. Governance, strategies and targets': 1.0,\n",
       " 'n_target - 4 - 4. Governance, strategies and targets': 67.0,\n",
       " 'ROC AUC - 4 - 5. Agreements': 1.0,\n",
       " 'precision - 4 - 5. Agreements': 1.0,\n",
       " 'recall - 4 - 5. Agreements': 1.0,\n",
       " 'F1 - 4 - 5. Agreements': 1.0,\n",
       " 'accuracy - 4 - 5. Agreements': 1.0,\n",
       " 'n_target - 4 - 5. Agreements': 23.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cv/df_588_cv_results_4 -_svm_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-389c6d41d6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'cv/df_{df.shape[0]}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minner_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_clf__class_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cv/df_588_cv_results_4 -_svm_0.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "args.resume=\"True\"\n",
    "k = 0\n",
    "fname = f'cv/df_{df.shape[0]}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "if args.resume:\n",
    "    inner_scores = pd.read_csv(fname)\n",
    "    best_model = inner_scores.sort_values('rank_test_score').to_dict('records')[0]\n",
    "    if best_model['param_clf__class_weight'] != \"balanced\":\n",
    "        best_model['param_clf__class_weight'] = ast.literal_eval(best_model['param_clf__class_weight'])\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = cvs.KFoldRandom(args.n_splits, df.index, nonrandom_index, discard=False)\n",
    "\n",
    "for k, (train, test) in enumerate(outer_cv):\n",
    "    if k!=rank_j:                                                                                                                                                                                            \n",
    "        continue                                                                                                                                                                                             \n",
    "#     inner_cv = cvs.KFoldRandom(args.n_splits, train, nonrandom_index, discard=False)                                                                                                                         \n",
    "#     clf = GridSearchCV(pipeline, parameters, scoring=\"f1\", n_jobs=8, verbose=1, cv=inner_cv)                                                                                                                 \n",
    "#     clf.fit(df.loc[train, 'content'], df.loc[train,'labels'])                                                                                                                                                \n",
    "\n",
    "#     inner_scores = pd.DataFrame(clf.cv_results_)\n",
    "#     fname = f'cv/df_{df.shape[0]}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "\n",
    "\n",
    "#     inner_scores.to_csv(fname, index=False)\n",
    "#     y_preds = clf.predict_proba(df.loc[test,'content'])#[:,1]                                                                                                                                                 \n",
    "#     if len(cols)==1:\n",
    "#         y_preds = y_preds[:,1]\n",
    "#     eps = cvs.evaluate_preds(df.loc[test,'labels'], y_pred, cols)\n",
    "#     best_params = inner_scores.sort_values('mean_test_score',ascending=False).to_dict('records')[0]['params']\n",
    "#     for key, value in best_params.items():\n",
    "#         eps[key] = value\n",
    "#     eps[\"rank_k\"] = rank_i\n",
    "\n",
    "\n",
    "#     fname = f'cv/df_{df.shape[0]}_cv_results_outer_nonrandom_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "#     pd.DataFrame.from_dict([eps]).to_csv(fname, index=False)\n",
    "#     fname = f'cv/df_{df.shape[0]}_y_preds_nonrandom_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}'\n",
    "#     np.save(fname,y_preds)\n",
    "#     fname = f'cv/df_{df.shape[0]}_y_pred_nonrandom_ids_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}'\n",
    "#     np.save(fname,df.loc[test,\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume = \"True\"\n",
    "fname = f'cv/df_{df.shape[0]}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "if args.resume==\"True\":\n",
    "\tinner_scores = pd.read_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': 9.53432289759318,\n",
       " 'mean_score_time': 0.9220480918884276,\n",
       " 'mean_test_score': 0.7097106654117254,\n",
       " 'mean_train_score': 0.8124689253447457,\n",
       " 'param_clf__C': 100.0,\n",
       " 'param_clf__class_weight': 'balanced',\n",
       " 'param_clf__gamma': 0.001,\n",
       " 'param_clf__kernel': 'rbf',\n",
       " 'param_vect__max_df': 0.75,\n",
       " 'param_vect__min_df': 15,\n",
       " 'param_vect__ngram_range': '(1, 1)',\n",
       " 'params': \"{'clf__C': 100.0, 'clf__class_weight': 'balanced', 'clf__gamma': 0.001, 'clf__kernel': 'rbf', 'vect__max_df': 0.75, 'vect__min_df': 15, 'vect__ngram_range': (1, 1)}\",\n",
       " 'rank_test_score': 3,\n",
       " 'split0_test_score': 0.7246376811594203,\n",
       " 'split0_train_score': 0.81875,\n",
       " 'split1_test_score': 0.7447154471544716,\n",
       " 'split1_train_score': 0.7984000000000001,\n",
       " 'split2_test_score': 0.6597131681877445,\n",
       " 'split2_train_score': 0.8202567760342369,\n",
       " 'std_fit_time': 0.14415523327554391,\n",
       " 'std_score_time': 0.016128296744403837,\n",
       " 'std_test_score': 0.036269105441615386,\n",
       " 'std_train_score': 0.009967232607277214}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = inner_scores.sort_values('rank_test_score').to_dict('records')[0]\n",
    "if best_model['param_clf__class_weight'] != \"balanced\":\n",
    "    best_model['param_clf__class_weight'] = ast.literal_eval(best_model['param_clf__class_weight'])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__norm', 'vect__preprocessor', 'vect__smooth_idf', 'vect__stop_words', 'vect__strip_accents', 'vect__sublinear_tf', 'vect__token_pattern', 'vect__tokenizer', 'vect__use_idf', 'vect__vocabulary', 'clf__C', 'clf__break_ties', 'clf__cache_size', 'clf__class_weight', 'clf__coef0', 'clf__decision_function_shape', 'clf__degree', 'clf__gamma', 'clf__kernel', 'clf__max_iter', 'clf__probability', 'clf__random_state', 'clf__shrinking', 'clf__tol', 'clf__verbose'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6f4e4cfcb961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/software/django-tmv/tmv/venv/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/django-tmv/tmv/venv/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/django-tmv/tmv/venv/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/software/django-tmv/tmv/venv/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ast\n",
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        max_df=best_model['param_vect__max_df'],\n",
    "        min_df=best_model['param_vect__min_df'],\n",
    "        ngram_range=ast.literal_eval(best_model['param_vect__ngram_range'])\n",
    "    )),\n",
    "    ('clf', SVC(\n",
    "        probability=True,\n",
    "        C=best_model['param_clf__C'],\n",
    "        class_weight=best_model['param_clf__class_weight'],\n",
    "        kernel=best_model['param_clf__kernel'],\n",
    "        gamma=best_model['param_clf__gamma']\n",
    "    )),    \n",
    "])\n",
    "\n",
    "clf.fit(df.loc[train,'content'],df.loc[train,'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Increased social and environmental vulnerabili...\n",
       "1       There exists guarded. agreement that climate c...\n",
       "2       This issue of Agricultural Economics is a spec...\n",
       "3       Emerging ridesharing travel could be an effect...\n",
       "4       First generation biofuels are widely available...\n",
       "                              ...                        \n",
       "2504    This study aims to analyze greenhouse gas emis...\n",
       "2505    The paper describes the state-of-the-art of ex...\n",
       "2507    Deforestation of tropical forest is serious pr...\n",
       "2508    Quantitative simulations of the global-scale b...\n",
       "2511    A detailed description of the European Commiss...\n",
       "Name: content, Length: 2282, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[train,'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.Name object at 0x7efcb11c3e10>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-faaf927d324d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_clf__class_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: <_ast.Name object at 0x7efcb11c3e10>"
     ]
    }
   ],
   "source": [
    "best_model['param_clf__class_weight']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
