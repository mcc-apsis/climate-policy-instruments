{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b439d4b-ca48-4df7-a439-56a7947650e7",
   "metadata": {},
   "source": [
    "## Tuning threshold\n",
    "\n",
    "This notebook demonstrates the intended threshold tuning mechanism:\n",
    "\n",
    "- For each outer fold:\n",
    "    - Choose the best model with ROC AUC\n",
    "    - For each inner fold:\n",
    "        - make predictions\n",
    "        - for each threshold:\n",
    "            - calculate metrics\n",
    "    - Calculate best threshold on average\n",
    "    - Calculate metrics of best model with best threshold against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da61229-9928-414a-b91b-57666d91a0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7f6c16-edcf-4faa-90b5-2ac7c661f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv_setup_simplified as cvs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f35b4a4f-9423-4d25-b7a2-8090317f3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    pass\n",
    "args.model_name = \"climatebert/distilroberta-base-climate-f\"\n",
    "#args.model_name = \"distilbert-base-uncased\"\n",
    "args.y_prefix = \"INCLUDE\"\n",
    "#.y_prefix = \"4 -\"\n",
    "args.n_splits = 3\n",
    "args.make_predictions = False\n",
    "args.roundup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25a015f2-61ae-417d-b78c-a2d5c1d65908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Rank I  2 Rank j 2\n",
      "(2513, 104)\n",
      "seen_index Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "            ...\n",
      "            2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512],\n",
      "           dtype='int64', length=2513)\n",
      "nonrandom_index Int64Index([   0,    1,    2,    3,    4,    7,    8,   10,   11,   12,\n",
      "            ...\n",
      "            2495, 2498, 2500, 2503, 2504, 2505, 2507, 2508, 2510, 2512],\n",
      "           dtype='int64', length=1811)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Establish what task number we have if running from slurm, otherwise just get a random number\n",
    "# This means we are just running the script in test mode\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    test = False\n",
    "except:\n",
    "    import random\n",
    "    rank = random.randint(0,args.n_splits**2)\n",
    "    print(rank)\n",
    "    test = True\n",
    "    \n",
    "rank_i = rank%args.n_splits\n",
    "rank_j = rank//args.n_splits\n",
    "\n",
    "print(\"Rank I \", rank_i, \"Rank j\", rank_j)\n",
    "# Import the rest of the libraries\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "seen_df = pd.read_csv('../data/0_labelled_documents.csv')\n",
    "\n",
    "seen_df = (seen_df\n",
    "      .sort_values('id')\n",
    "      .sample(frac=1, random_state=1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "weights_df = pd.read_csv('../data/0_label_weights.csv')\n",
    "\n",
    "# Get the target labels from the y_prefix argument passed to this script\n",
    "if len(args.y_prefix) < 2:\n",
    "    args.y_prefix+=\" \"\n",
    "cols = [x for x in seen_df.columns if re.match(f\"^{args.y_prefix}\",x)]\n",
    "\n",
    "\n",
    "# If the target is inclusion, use only those documents for which we have a non-na value\n",
    "# Otherwise, only use those documents which are included\n",
    "# also define what subset is to be treated as a random representative sample\n",
    "# For labels beyond inclusion, we treat all those that are representative of the included\n",
    "# studies as representative\n",
    "if \"INCLUDE\" in args.y_prefix:\n",
    "    y_var = cols[0]\n",
    "    seen_df = seen_df.loc[pd.notna(seen_df[y_var]),:].reset_index(drop=True)\n",
    "    seen_df['random'] = seen_df['representative_sample']\n",
    "else:\n",
    "    seen_df = seen_df[seen_df['INCLUDE']==1]\n",
    "    seen_df['random'] = seen_df['representative_relevant']\n",
    "    \n",
    "\n",
    "# Turn the columns into target variables and get class-weights to counteract class imbalances\n",
    "if len(cols)==1:\n",
    "    y_var = cols[0]\n",
    "    seen_df = seen_df.loc[pd.notna(seen_df[y_var]),:].reset_index(drop=True)\n",
    "    print(seen_df.shape)\n",
    "    seen_df['labels'] = list(seen_df[y_var].values.astype(int))\n",
    "    cw = seen_df[(seen_df['random']==1) & (seen_df[y_var]==0)].shape[0] / seen_df[(seen_df['random']==1) & (seen_df[y_var]==1)].shape[0]\n",
    "    class_weight={1:cw}\n",
    "    scorer = \"F1\"\n",
    "    weights_df[\"sample_weight\"] = list(weights_df[y_var+\"_sample_weight\"].fillna(1).values)\n",
    "else:\n",
    "    num_labels = len(cols) \n",
    "    weights_df['sample_weight'] = list(weights_df[[x+\"_sample_weight\" for x in cols]].fillna(1).values)\n",
    "    seen_df = seen_df.replace(2,1)\n",
    "    seen_df['labels'] = list(seen_df[cols].values.astype(int))\n",
    "    seen_df = seen_df.dropna(subset=cols)\n",
    "    seen_df = seen_df.reset_index(drop=True)\n",
    "    scorer = \"ROC AUC macro\"\n",
    "    class_weight = {}\n",
    "    for i, t in enumerate(cols):\n",
    "        cw = seen_df[(seen_df['random']==1) & (seen_df[t]==0)].shape[0] / seen_df[(seen_df['random']==1) & (seen_df[t]==1)].shape[0]\n",
    "        class_weight[i] = cw\n",
    "\n",
    "# Remove unneccessary columns\n",
    "seen_df = seen_df[[\"id\",\"title\",\"content\",\"labels\",\"random\"]+cols].merge(\n",
    "    weights_df[[\"doc__id\",\"sample_weight\"]].rename(columns={\"doc__id\":\"id\"})\n",
    ")    \n",
    "\n",
    "\n",
    "# Merge with the unseen data if necessary\n",
    "seen_df['seen']  = 1\n",
    "if args.make_predictions==\"True\":\n",
    "    unseen_df = pd.read_csv('../data/0_unlabelled_documents.csv')\n",
    "    unseen_df['seen'] = 0\n",
    "    df = (pd.concat([seen_df,unseen_df])\n",
    "          .sort_values('id')\n",
    "          .sample(frac=1, random_state=1)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    df.content = df.content.astype(str)\n",
    "else:\n",
    "    df = seen_df\n",
    "\n",
    "# This is the index of nonrandom/nonrepresentative documents, and these will be removed from validation sets\n",
    "nonrandom_index = df[(df['random']!=1) & (df['seen']==1)].index\n",
    "random_index = df[df['random']==1].index\n",
    "seen_index = df[df['seen']==1].index\n",
    "unseen_index = df[df['seen']==0].index\n",
    "\n",
    "print(\"seen_index\", seen_index)\n",
    "print(\"nonrandom_index\", nonrandom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8821854-593b-4293-8e8a-c37c59d44217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bde9b358-3fa8-449d-82d6-a11aef218a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from this round:  {'class_weight': {1: 14.954545454545455}, 'sample_weighted': True, 'batch_size': 16, 'weight_decay': 0.1, 'learning_rate': 7e-05, 'num_epochs': 4}\n",
      "Best model from this round:  {'class_weight': {1: 14.954545454545455}, 'sample_weighted': False, 'batch_size': 32, 'weight_decay': 0.1, 'learning_rate': 5e-05, 'num_epochs': 5}\n",
      "Best model from this round:  {'class_weight': {1: 14.954545454545455}, 'sample_weighted': True, 'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 2e-05, 'num_epochs': 7}\n"
     ]
    }
   ],
   "source": [
    "import cv_setup as cvs\n",
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "# Get the BERT parameters, and include class_weight as a parameter to be tested\n",
    "bert_params = cvs.bert_params\n",
    "bert_params['class_weight'].append(class_weight)\n",
    "bert_params['class_weight'] = [class_weight]\n",
    "param_space = list(cvs.product_dict(**bert_params))\n",
    "params = list(bert_params.keys())\n",
    "\n",
    "outer_cv = cvs.KFoldRandom(args.n_splits, seen_index, nonrandom_index, discard=False)\n",
    "\n",
    "# Iterate through the folds\n",
    "for k, (train, test) in enumerate(outer_cv):   \n",
    "    inner_scores = []\n",
    "    for l in range(args.n_splits):\n",
    "        fname = f'cv/df_{len(seen_index)}_cv_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}_{l}.csv'\n",
    "        inner_df = pd.read_csv(fname)\n",
    "        inner_df = inner_df.sort_values(scorer,ascending=False).reset_index(drop=True)\n",
    "        inner_scores += inner_df.to_dict('records')\n",
    "\n",
    "    inner_scores = pd.DataFrame.from_dict(inner_scores).fillna(-1)\n",
    "    best_model = (inner_scores\n",
    "                  .groupby(params)[scorer]\n",
    "                  .mean()\n",
    "                  .sort_values(ascending=False)\n",
    "                  .reset_index() \n",
    "                 ).to_dict('records')[0]\n",
    "    \n",
    "    del best_model[scorer]\n",
    "    if best_model['class_weight']==-1:\n",
    "        best_model['class_weight']=None\n",
    "    elif isinstance(best_model['class_weight'],str):\n",
    "        best_model['class_weight'] = ast.literal_eval(best_model['class_weight'])\n",
    "    \n",
    "    print(\"Best model from this round: \", best_model)\n",
    "\n",
    "    inner_cv = cvs.KFoldRandom(args.n_splits, train, nonrandom_index, discard=False)\n",
    "    inner_scores = []\n",
    "    \n",
    "    threshold_results = []\n",
    "    \n",
    "    for l, (l_train, l_test) in enumerate(inner_cv):\n",
    "        # outer_scores, y_preds = cvs.train_eval_bert(\n",
    "        #     #args.model_name, \n",
    "        #     \"distilbert-base-uncased\",\n",
    "        #     best_model, df=df, targets=cols, \n",
    "        #     train=l_train, test=l_test, roundup=args.roundup, return_predictions=True\n",
    "        # )\n",
    "        \n",
    "        if \"INCLUDE\" in args.y_prefix:\n",
    "            y_preds = np.zeros((len(l_test),2))\n",
    "            y_preds[:,1] = np.random.uniform(size=len(l_test))\n",
    "            y_preds[:,0] = 1 - y_preds[:,1]\n",
    "            for t in np.linspace(0.1, 0.9, 50):\n",
    "                y_pred_bin = np.where(y_preds[:,1]>t,1,0)\n",
    "                threshold_results.append({\n",
    "                    \"t\": t, \n",
    "                    \"f1\": f1_score(df['labels'][l_test], y_pred_bin),\n",
    "                    \"k\": l,\n",
    "                    \"label_i\": 0\n",
    "                })\n",
    "        else:\n",
    "            y_preds = np.zeros((len(l_test),num_labels))\n",
    "            for label_i, col in enumerate(cols):\n",
    "                y_preds[:,label_i] = np.random.uniform(size=len(l_test))                \n",
    "                for t in np.linspace(0.1, 0.9, 50):\n",
    "                    y_pred_bin = np.where(y_preds[:,label_i]>t,1,0)\n",
    "                    y_true = [x[label_i] for x in df.labels[l_test]]\n",
    "                    threshold_results.append({\n",
    "                        \"t\": t, \n",
    "                        \"f1\": f1_score(y_true, y_pred_bin),\n",
    "                        \"k\": l,\n",
    "                        \"label_i\": label_i\n",
    "                    })\n",
    "            \n",
    "    thresh_df = pd.DataFrame.from_dict(threshold_results)\n",
    "    optimal_t = (thresh_df.groupby([\"label_i\",\"t\"])[\"f1\"]\n",
    "     .mean()\n",
    "     .sort_values(ascending=False)\n",
    "     .reset_index()\n",
    "     .groupby([\"label_i\"])\n",
    "     .first()\n",
    "    )\n",
    "    fname = f'cv/df_{len(seen_index)}_tune_results_{args.y_prefix}_{args.model_name.replace(\"/\",\"__\")}_{k}.csv'\n",
    "    thresh_df.to_csv(fname, index=False)\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "390f1662-45e5-4f1e-a04d-7a317ecbd198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81836735])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0797872-32c2-4c75-9cf9-fc2dbc387d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45676/2335492641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "f1_score(df[\"labels\"][l_test], y_preds.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baaf9e9a-f4eb-447d-95f5-c71898471162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_i  t       \n",
       "0        0.165306    0.671711\n",
       "         0.100000    0.670946\n",
       "         0.116327    0.669059\n",
       "         0.181633    0.666093\n",
       "         0.148980    0.663371\n",
       "                       ...   \n",
       "2        0.802041    0.018018\n",
       "         0.785714    0.015873\n",
       "         0.769388    0.015152\n",
       "         0.753061    0.014493\n",
       "         0.736735    0.013072\n",
       "Name: f1, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_df = pd.DataFrame.from_dict(threshold_results)\n",
    "thresh_df.groupby([\"label_i\",\"t\"])[\"f1\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e9db3aa-13ec-411e-92d5-e2a1f8655934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165306</td>\n",
       "      <td>0.671711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.303203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508163</td>\n",
       "      <td>0.087644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116327</td>\n",
       "      <td>0.572968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181633</td>\n",
       "      <td>0.341797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                t        f1\n",
       "label_i                    \n",
       "0        0.165306  0.671711\n",
       "1        0.100000  0.303203\n",
       "2        0.508163  0.087644\n",
       "3        0.116327  0.572968\n",
       "4        0.181633  0.341797"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_t = (thresh_df.groupby([\"label_i\",\"t\"])[\"f1\"]\n",
    " .mean()\n",
    " .sort_values(ascending=False)\n",
    " .reset_index()\n",
    " .groupby([\"label_i\"])\n",
    " .first()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9c839b3-d69d-48f9-9569-06edf2d5e222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_df = pd.DataFrame.from_dict(threshold_results)\n",
    "optimal_t = thresh_df.groupby(\"t\")[\"f1\"].mean().sort_values(ascending=False).index[:1].values\n",
    "optimal_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5480a94b-35a8-4151-85d8-b3d6bab9a3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1938433 , 0.04409522, 0.87590919, ..., 0.65369151, 0.39914938,\n",
       "       0.11373069])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.random.uniform(size=len(train))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edadb523-99e5-492f-8ea6-eb720cec225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27605815, 0.72394185],\n",
       "       [0.98910636, 0.01089364],\n",
       "       [0.31293071, 0.68706929],\n",
       "       ...,\n",
       "       [0.65493963, 0.34506037],\n",
       "       [0.35898006, 0.64101994],\n",
       "       [0.62577374, 0.37422626]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros((len(train),2))\n",
    "y_pred[:,1] = np.random.uniform(size=len(train))\n",
    "y_pred[:,0] = 1 - y_pred[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b2b98f7-9302-425b-bd1f-f65100b827d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3eadd0b7074cdaa707e5cd9a55ce8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of 'distilbert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'distilbert-base-uncased' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    615\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1243\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontent_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     progress = tqdm(\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/tqdm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"disable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mcolour\u001b[0;34m(self, bar_color)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'container'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbar_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FloatProgress' object has no attribute 'style'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39874/1903708554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"distilbert-base-uncased\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m             config, model_kwargs = cls.config_class.from_pretrained(\n\u001b[0m\u001b[1;32m   2013\u001b[0m                 \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             logger.warning(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    636\u001b[0m                     \u001b[0;34mf\"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'distilbert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'distilbert-base-uncased' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "num_labels = 2\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, cache_dir=\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27293b-f91d-4d02-938b-d31af87f4706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d3b97-8dc7-4b9f-96a9-a8a217c285c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
